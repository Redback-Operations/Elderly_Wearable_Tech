{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8f4dfc-bd04-4601-97ae-fb0741549b1e",
   "metadata": {},
   "source": [
    "# Sleep Analysis with inertial wrist-worn sensors (photoplethysmographic(PPG) sensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ab03b-40df-4476-8efb-af7619d0ee82",
   "metadata": {},
   "source": [
    "## Importing Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d1c4ca-647e-41f6-b66e-a8f9e893c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a40ac7-5fe1-45ac-9c1f-e687a79fe9d3",
   "metadata": {},
   "source": [
    "## Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa6160-961d-4af7-9535-ad2628b39352",
   "metadata": {},
   "source": [
    "### Statistical features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072db517-e018-4b75-93d2-cf21a924cccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1246 entries, 0 to 1245\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   SubNo                1246 non-null   int64  \n",
      " 1   SegNo                1246 non-null   int64  \n",
      " 2   MeanAbsDev           1246 non-null   float64\n",
      " 3   MedianAbsDev         1246 non-null   float64\n",
      " 4   InterquartileRange   1246 non-null   float64\n",
      " 5   centralMoment        1246 non-null   float64\n",
      " 6   averageCurveLength   1246 non-null   float64\n",
      " 7   averageEnergy        1246 non-null   float64\n",
      " 8   averageTeagerEnergy  1246 non-null   float64\n",
      " 9   shapeFactor          1246 non-null   float64\n",
      " 10  meanValue            1246 non-null   float64\n",
      " 11  sdValue              1246 non-null   float64\n",
      " 12  rmsValue             1246 non-null   float64\n",
      " 13  tmean25              1246 non-null   float64\n",
      " 14  tmean50              1246 non-null   float64\n",
      " 15  geometricMean        1246 non-null   float64\n",
      " 16  harmonicMean         1246 non-null   float64\n",
      " 17  maxValue             1246 non-null   float64\n",
      " 18  minValue             1246 non-null   float64\n",
      " 19  svdPPG               1246 non-null   float64\n",
      " 20  skewPPG              1246 non-null   float64\n",
      " 21  kurtPPG              1246 non-null   float64\n",
      " 22  PoincareSD1          1246 non-null   float64\n",
      " 23  PoincareSD2          1246 non-null   float64\n",
      " 24  ratioSD1SD2          1246 non-null   float64\n",
      " 25  CCM                  1246 non-null   float64\n",
      " 26  HjorthActivity       1246 non-null   float64\n",
      " 27  HjorthMobility       1246 non-null   float64\n",
      " 28  HjorthComplexity     1246 non-null   float64\n",
      " 29  lam                  1246 non-null   float64\n",
      " 30  HFD                  1246 non-null   float64\n",
      " 31  KFD                  1246 non-null   float64\n",
      " 32  Class                1246 non-null   int64  \n",
      "dtypes: float64(30), int64(3)\n",
      "memory usage: 321.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   SubNo  SegNo  MeanAbsDev  MedianAbsDev  InterquartileRange  centralMoment  \\\n",
       " 0      1      1    0.912767      0.001655            2.192423      22.657364   \n",
       " 1      1      2    0.756760      0.558465            1.127156    1432.670278   \n",
       " 2      1      3    0.759760      0.556348            1.112695    1753.272469   \n",
       " 3      1      4    0.761878      0.570325            1.133696    2110.583808   \n",
       " 4      1      5    0.905395      0.003289            2.193957      26.877642   \n",
       " \n",
       "    averageCurveLength  averageEnergy  averageTeagerEnergy  shapeFactor  ...  \\\n",
       " 0       -6.406334e-16            1.0              0.99987     0.149008  ...   \n",
       " 1        2.310716e-12            1.0              0.99987    -0.030211  ...   \n",
       " 2       -3.698185e-12            1.0              0.99987    -0.034199  ...   \n",
       " 3        4.579237e-12            1.0              0.99987    -0.031477  ...   \n",
       " 4       -3.697794e-15            1.0              0.99987    -0.157957  ...   \n",
       " \n",
       "    PoincareSD2  ratioSD1SD2           CCM  HjorthActivity  HjorthMobility  \\\n",
       " 0  1411.941562     0.039988  1.227427e-08             1.0        0.010411   \n",
       " 1   915.793357     1.033208  3.773205e-07             1.0        1.329995   \n",
       " 2   996.863622     1.002636  3.976335e-07             1.0        1.323966   \n",
       " 3  1017.009484     0.920768  3.485810e-07             1.0        1.328367   \n",
       " 4  1411.574303     0.044405  1.406714e-08             1.0        0.011125   \n",
       " \n",
       "    HjorthComplexity         lam       HFD       KFD  Class  \n",
       " 0         41.021530  136.561423  1.300122  1.000006      6  \n",
       " 1          1.251437   84.029234  1.994388  1.055329      6  \n",
       " 2          1.264635   83.635191  1.997516  1.055113      6  \n",
       " 3          1.260437   87.537957  1.995013  1.055506      6  \n",
       " 4         57.923784  112.121415  1.390540  1.000007      6  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       " None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STATISTICAL_FEATURES = pd.read_excel(\"C:/Users/chspr/Downloads/SleepStagingStatisticalFeatures.xlsx\")\n",
    "\n",
    "STATISTICAL_FEATURES.head(), STATISTICAL_FEATURES.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d986c2-07d2-416c-a274-08dad7859398",
   "metadata": {},
   "source": [
    "these are the statistical features which are extracted from photoplethysmographic(PPG) sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd32ac-6c82-4c1f-8b4f-11bdd32897ec",
   "metadata": {},
   "source": [
    "### Cardio- respiratory features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4522152-d273-4104-b2d1-1de13d4e2d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1246 entries, 0 to 1245\n",
      "Data columns (total 33 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   SubNo                1246 non-null   int64  \n",
      " 1   SegNo                1246 non-null   int64  \n",
      " 2   MeanAbsDev           1246 non-null   float64\n",
      " 3   MedianAbsDev         1246 non-null   float64\n",
      " 4   InterquartileRange   1246 non-null   float64\n",
      " 5   centralMoment        1246 non-null   float64\n",
      " 6   averageCurveLength   1246 non-null   float64\n",
      " 7   averageEnergy        1246 non-null   float64\n",
      " 8   averageTeagerEnergy  1246 non-null   float64\n",
      " 9   shapeFactor          1246 non-null   float64\n",
      " 10  meanValue            1246 non-null   float64\n",
      " 11  sdValue              1246 non-null   float64\n",
      " 12  rmsValue             1246 non-null   float64\n",
      " 13  tmean25              1246 non-null   float64\n",
      " 14  tmean50              1246 non-null   float64\n",
      " 15  geometricMean        1246 non-null   float64\n",
      " 16  harmonicMean         1246 non-null   float64\n",
      " 17  maxValue             1246 non-null   float64\n",
      " 18  minValue             1246 non-null   float64\n",
      " 19  svdPPI               1246 non-null   float64\n",
      " 20  skewPPI              1246 non-null   float64\n",
      " 21  kurtPPI              1246 non-null   float64\n",
      " 22  PoincareSD1          1246 non-null   float64\n",
      " 23  PoincareSD2          1246 non-null   float64\n",
      " 24  ratioSD1SD2          1246 non-null   float64\n",
      " 25  CCM                  1246 non-null   float64\n",
      " 26  HjorthActivity       1246 non-null   float64\n",
      " 27  HjorthMobility       1246 non-null   float64\n",
      " 28  HjorthComplexity     1246 non-null   float64\n",
      " 29  lam                  1246 non-null   float64\n",
      " 30  HFD                  1246 non-null   float64\n",
      " 31  KFD                  1246 non-null   float64\n",
      " 32  Class                1246 non-null   int64  \n",
      "dtypes: float64(30), int64(3)\n",
      "memory usage: 321.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   SubNo  SegNo  MeanAbsDev  MedianAbsDev  InterquartileRange  centralMoment  \\\n",
       " 0      1      1    0.912767      0.001655            2.192423      22.657364   \n",
       " 1      1      2    0.756760      0.558465            1.127156    1432.670278   \n",
       " 2      1      3    0.759760      0.556348            1.112695    1753.272469   \n",
       " 3      1      4    0.761878      0.570325            1.133696    2110.583808   \n",
       " 4      1      5    0.905395      0.003289            2.193957      26.877642   \n",
       " \n",
       "    averageCurveLength  averageEnergy  averageTeagerEnergy  shapeFactor  ...  \\\n",
       " 0       -6.406334e-16            1.0              0.99987     0.149008  ...   \n",
       " 1        2.310716e-12            1.0              0.99987    -0.030211  ...   \n",
       " 2       -3.698185e-12            1.0              0.99987    -0.034199  ...   \n",
       " 3        4.579237e-12            1.0              0.99987    -0.031477  ...   \n",
       " 4       -3.697794e-15            1.0              0.99987    -0.157957  ...   \n",
       " \n",
       "    PoincareSD2  ratioSD1SD2           CCM  HjorthActivity  HjorthMobility  \\\n",
       " 0  1411.941562     0.039988  1.227427e-08             1.0        0.010411   \n",
       " 1   915.793357     1.033208  3.773205e-07             1.0        1.329995   \n",
       " 2   996.863622     1.002636  3.976335e-07             1.0        1.323966   \n",
       " 3  1017.009484     0.920768  3.485810e-07             1.0        1.328367   \n",
       " 4  1411.574303     0.044405  1.406714e-08             1.0        0.011125   \n",
       " \n",
       "    HjorthComplexity         lam       HFD       KFD  Class  \n",
       " 0         41.021530  136.561423  1.300122  1.000006      6  \n",
       " 1          1.251437   84.029234  1.994388  1.055329      6  \n",
       " 2          1.264635   83.635191  1.997516  1.055113      6  \n",
       " 3          1.260437   87.537957  1.995013  1.055506      6  \n",
       " 4         57.923784  112.121415  1.390540  1.000007      6  \n",
       " \n",
       " [5 rows x 33 columns],\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CARDIO_RESPIRATORY_FEATURES = pd.read_excel(\"C:/Users/chspr/Downloads/SleepStagingCardioRespiratoryFeatures.xlsx\")\n",
    "\n",
    "CARDIO_RESPIRATORY_FEATURES.head(), CARDIO_RESPIRATORY_FEATURES.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de89f50-88a7-44fd-b61f-606e5bd0712f",
   "metadata": {},
   "source": [
    "these are the surrogate cardiorespiratory features extracted from photoplethysmographic(PPG) sensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f9e5c-af5d-443e-935d-d3fe92227810",
   "metadata": {},
   "source": [
    "### Arterial features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5536f736-d87c-4f52-ab82-61260f5d1150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1246 entries, 0 to 1245\n",
      "Data columns (total 25 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   SubNo       1246 non-null   int64  \n",
      " 1   SegNo       1246 non-null   int64  \n",
      " 2   AVppAmp     1246 non-null   float64\n",
      " 3   SDppAmp     1246 non-null   float64\n",
      " 4   SDSDppAmp   1246 non-null   float64\n",
      " 5   RMSSDppAmp  1246 non-null   float64\n",
      " 6   AVpw        1246 non-null   float64\n",
      " 7   SDpw        1246 non-null   float64\n",
      " 8   SDSDpw      1246 non-null   float64\n",
      " 9   RMSSDpw     1246 non-null   float64\n",
      " 10  meanA1      1246 non-null   float64\n",
      " 11  stdA1       1246 non-null   float64\n",
      " 12  meanA2      1246 non-null   float64\n",
      " 13  stdA2       1246 non-null   float64\n",
      " 14  meanArea    1246 non-null   float64\n",
      " 15  stdArea     1246 non-null   float64\n",
      " 16  meanIPAR    1246 non-null   float64\n",
      " 17  stdIPAR     1246 non-null   float64\n",
      " 18  meanT1      1246 non-null   float64\n",
      " 19  stdT1       1246 non-null   float64\n",
      " 20  meanT2      1246 non-null   float64\n",
      " 21  stdT2       1246 non-null   float64\n",
      " 22  meanIPTR    1246 non-null   float64\n",
      " 23  stdIPTR     1246 non-null   float64\n",
      " 24  Class       1246 non-null   int64  \n",
      "dtypes: float64(22), int64(3)\n",
      "memory usage: 243.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(   SubNo  SegNo   AVppAmp   SDppAmp  SDSDppAmp  RMSSDppAmp      AVpw  \\\n",
       " 0      1      1  0.006709  0.000979   0.000804    0.001411  0.449183   \n",
       " 1      1      2  4.641927  0.707311   0.602373    0.987717  0.415554   \n",
       " 2      1      3  4.576796  0.620150   0.536944    0.855869  0.456689   \n",
       " 3      1      4  4.624681  0.764361   0.624150    1.026587  0.480042   \n",
       " 4      1      5  0.019445  0.012603   0.009917    0.011559  0.480410   \n",
       " \n",
       "        SDpw    SDSDpw   RMSSDpw  ...    stdArea  meanIPAR   stdIPAR  \\\n",
       " 0  0.132442  0.070278  0.102845  ...   0.189781  2.029144  3.688051   \n",
       " 1  0.122198  0.048761  0.083460  ...  43.496371  2.604393  4.634970   \n",
       " 2  0.121285  0.066370  0.108959  ...  41.207404  1.887720  3.364893   \n",
       " 3  0.138293  0.069621  0.136883  ...  58.421931  2.110984  2.799883   \n",
       " 4  0.118619  0.069744  0.107834  ...   5.805060  2.203302  3.527049   \n",
       " \n",
       "       meanT1      stdT1     meanT2      stdT2  meanIPTR   stdIPTR  Class  \n",
       " 0  26.158333  19.155548  22.216667  14.379067  1.976787  3.628978      6  \n",
       " 1  23.287342  14.096793  23.520253  15.183235  2.645773  4.849708      6  \n",
       " 2  26.347973  15.622294  24.029054  16.438907  1.909369  3.572883      6  \n",
       " 3  24.895333  17.392186  24.774000  16.051954  2.145320  2.919238      6  \n",
       " 4  26.808571  15.404135  26.881429  17.412985  2.211676  3.471947      6  \n",
       " \n",
       " [5 rows x 25 columns],\n",
       " None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ARTERIAL_FEATURES = pd.read_excel(\"C:/Users/chspr/Downloads/SleepStagingArterialFeatures.xlsx\")\n",
    "\n",
    "ARTERIAL_FEATURES.head(), ARTERIAL_FEATURES.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1399a64e-69f1-43b3-9e97-1b62b3ddade9",
   "metadata": {},
   "source": [
    "these are the surrogate arterial blood pressure features extracted from photoplethysmographic(PPG) sensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa667d-faec-46b8-8b66-f0a8d47d3f42",
   "metadata": {},
   "source": [
    "## summary of datasets\n",
    "\n",
    "### statistical features\n",
    "The Statistical Features dataset contains 1,246 entries and 33 columns. All the columns have complete data with no missing values. The columns include various statistical measures like Mean Absolute Deviation, Interquartile Range, central moments, and many others. The last column, \"Class,\" seems to represent the sleep stage classification.\n",
    "\n",
    "#### column description\n",
    "\n",
    "SubNo:Subject ID,\n",
    "SegNo: Segment ID,\n",
    "MeanAbsDev: mean absolute deviation of PPG signal (mV),\n",
    "MedianAbsDev: median absolute deviation of PPG signal (mV),\n",
    "InterquartileRange: Interquartile Range of PPG signal (mV), \n",
    "centralMoment: central Moment of PPG signal,\n",
    "averageCurveLength: average Curve Length of PPG signal,\n",
    "averageEnergy: average Energy of PPG signal,\n",
    "averageTeagerEnergy : average Teager Energy of PPG signal,\n",
    "shapeFactor : shape Factorof PPG signal,\n",
    "meanValue : mean Value of PPG signal (mV),\n",
    "sdValue : standard deviation of PPG signal (mV),\n",
    "rmsValue : root mean squire of PPG signal (mV) ,\n",
    "tmean25 : 25 % trimmed mean of PPG signal (mV) ,\n",
    "tmean50 : 50 % trimmed mean of PPG signal (mV),\n",
    "geometricMean : geometric Mean of PPG signal (mV),\n",
    "harmonicMean : harmonic Mean of PPG signal (mV) ,\n",
    "maxValue : max Value of PPG signal (mV) ,\n",
    "minValue : min Value of PPG signal (mV),\n",
    "svdPPG : singular value decomposition of PPG signal,\n",
    "skewPPG : skewness of PPG signal,\n",
    "kurtPPG : kurtosis of PPG signal ,\n",
    "PoincareSD1 : Poincare SD1 of PPG signal,\n",
    "PoincareSD2 : Poincare SD1 of PPG signal ,\n",
    "ratioSD1SD2 : Ration of.Poincare SD1 and SD2 of PPG signal ,\n",
    "CCM : Complex correlation measure of PPG signal,\n",
    "HjorthActivity : Hjorth Activity of PPG signal ,\n",
    "HjorthMobility : Hjorth Mobility of PPG signal,\n",
    "HjorthComplexity : Hjorth Complexity of PPG signal,\n",
    "lam : Lyapunov exponent of PPG signal,\n",
    "HFD :Higuchi Fractal Dimension of PPG signal ,\n",
    "KFD : Katz?s fractal dimension of PPG signal ,\n",
    "Class: Label of class.\n",
    "\n",
    "\n",
    "### Cardio respiratory features\n",
    "the cardio respiratory features data contains 1246 entries and 33 columns same as statistical festures. this data types and cloumn names are mostly similar, with only slight differences in some features like svdPPI, skewPPI and kurtPPIU. this dataset also contains class cloumn which represents sleep stages.\n",
    "\n",
    "#### column description\n",
    "\n",
    "SubNo:Subject ID ,\n",
    "SegNo: Segment ID ,\n",
    "MeanAbsDev: mean absolute deviation of peak to peak interval (second) ,\n",
    "MedianAbsDev: median absolute deviation of peak to peak interval (second),\n",
    "InterquartileRange: Interquartile Range of peak to peak interval (second) ,\n",
    "centralMoment: central Moment of peak to peak interval ,\n",
    "averageCurveLength: average Curve Length of peak to peak interval ,\n",
    "averageEnergy: average Energy of peak to peak interval,\n",
    "averageTeagerEnergy : average Teager Energy of peak to peak interval,\n",
    "shapeFactor : shape Factor of peak to peak interval,\n",
    "meanValue : mean Value of peak to peak interval (second),\n",
    "sdValue : standard deviation of peak to peak interval (second),\n",
    "rmsValue : root mean squire of peak to peak interval (second),\n",
    "tmean25 : 25 % trimmed mean of peak to peak interval (second),\n",
    "tmean50 : 50 % trimmed mean of peak to peak interval (second),\n",
    "geometricMean : geometric Mean of peak to peak interval (second),\n",
    "harmonicMean : harmonic Mean of peak to peak interval (second),\n",
    "maxValue : max Value of peak to peak interval (second),\n",
    "minValue : min Value of peak to peak interval (second),\n",
    "svdPPI : singular value decomposition of peak to peak interval,\n",
    "skewPPI : skewness of peak to peak interval,\n",
    "kurtPPI : kurtosis of peak to peak interval,\n",
    "PoincareSD1 : Poincare SD1 of peak to peak interval,\n",
    "PoincareSD2 : Poincare SD1 of peak to peak interval,\n",
    "ratioSD1SD2 : Ration of.Poincare SD1 and SD2 of peak to peak interval,\n",
    "CCM : Complex correlation measure of peak to peak interval,\n",
    "HjorthActivity : Hjorth Activity of peak to peak interval,\n",
    "HjorthMobility : Hjorth Mobility of peak to peak interval,\n",
    "HjorthComplexity : Hjorth Complexity of peak to peak interval,\n",
    "lam : Lyapunov exponent of peak to peak interval,\n",
    "HFD :Higuchi Fractal Dimension of peak to peak interval,\n",
    "KFD : Katz?s fractal dimensionof peak to peak interval,\n",
    "Class: Label of class.\n",
    "\n",
    "### Arterial features\n",
    "the arterial features data contains 1246 entries and 25 columns. this dataaset includes features like AVppAmp, SDppAmp, various time-related features, and arterial properties. class column is present in this dataset also.\n",
    "\n",
    "#### cloumn description\n",
    "\n",
    "SubNo:Subject ID,\n",
    "SegNo: Segment ID,\n",
    "AVppAmp: Average peak to peak amplitude (mV),\n",
    "SDppAmp : standard deviation of peak to peak amplitude (mV),\n",
    "SDSDppAmp: standard deviation of successive difference of peak to peak amplitude (mV),\n",
    "RMSSDppAmp: Root mean square of successive difference of peak to peak amplitude (mV),\n",
    "AVpw: Average pulse width (second),\n",
    "SDpw: standard deviation of pulse width(second),\n",
    "SDSDpw: standard deviation of successive difference of pulse width (second),\n",
    "RMSSDpw: Root mean square of successive difference of pulse width (second),\n",
    "meanA1: average of the systolic area (mV-second),\n",
    "stdA1: standard deviation of systolic area (mV-second),\n",
    "meanA2: average of the diastolic area (mV-second),\n",
    "stdA2: standard deviation of diastolic area (mV-second),\n",
    "meanArea: average of PPG area (mV-second),\n",
    "stdArea: standard deviation of PPG area (mV-second),\n",
    "meanIPAR: average of inflection point area ratio,\n",
    "stdIPAR: standard deviation of inflection point area ratio,\n",
    "meanT1: average of systolic time (second),\n",
    "stdT1: standard deviation of systolic time (second),\n",
    "meanT2: average of diastolic time (second),\n",
    "stdT2: standard deviation of diastolic time (second),\n",
    "meanIPTR: average of inflection point time ratio,\n",
    "stdIPTR: standard deviation of inflection point time ratio,\n",
    "Class: Label of class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad913c61-e4da-4367-b502-be63b51ac054",
   "metadata": {},
   "source": [
    "## Merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8bc883a-55de-4aa7-b34e-7bd78a8b6cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "STATISTICAL_FEATURES_PATH = \"C:/Users/chspr/Downloads/SleepStagingStatisticalFeatures.xlsx\"\n",
    "CARDIO_RESPIRATORY_FEATURES_PATH = \"C:/Users/chspr/Downloads/SleepStagingCardioRespiratoryFeatures.xlsx\"\n",
    "ARTERIAL_FEATURES_PATH = \"C:/Users/chspr/Downloads/SleepStagingArterialFeatures.xlsx\"\n",
    "\n",
    "# Adjusting the sheet names to match between the files for accurate loading\n",
    "sheet_name_mapping = {\n",
    "    'Subject 1': 'Subject ID 1',\n",
    "    'Subject 2': 'Subject ID 2',\n",
    "    'Subject 3': 'Subject ID 3',\n",
    "    'Subject 4': 'Subject ID 4',\n",
    "    'Subject 5': 'Subject ID 5',\n",
    "    'Subject 6': 'Subject ID 6',\n",
    "    'Subject 7': 'Subject ID 7',\n",
    "    'Subject 8': 'Subject ID 8',\n",
    "    'Subject 9 ': 'Subject ID 9',\n",
    "    'Subject 10': 'Subject ID 10'\n",
    "}\n",
    "\n",
    "\n",
    "def merge_data(sheet_name_stat, sheet_name_cardio_art):\n",
    "    df_stat = pd.read_excel(STATISTICAL_FEATURES_PATH, sheet_name=sheet_name_stat)\n",
    "    df_cardio = pd.read_excel(CARDIO_RESPIRATORY_FEATURES_PATH, sheet_name=sheet_name_cardio_art)\n",
    "    df_art = pd.read_excel(ARTERIAL_FEATURES_PATH, sheet_name=sheet_name_cardio_art)\n",
    "    \n",
    "    # Merging dataframes on 'SubNo', 'SegNo', and 'Class'\n",
    "    df_merged = pd.merge(df_stat, df_cardio, on=['SubNo', 'SegNo', 'Class'], suffixes=('_stat', '_cardio'))\n",
    "    df_merged = pd.merge(df_merged, df_art, on=['SubNo', 'SegNo', 'Class'])\n",
    "    \n",
    "    # Moving 'Class' column to the end\n",
    "    class_col = df_merged.pop('Class')\n",
    "    df_merged['Class'] = class_col\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f290a8-8a2a-4572-b620-e7cab6527d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging sheets for each subject\n",
    "merged_data = {name: merge_data(name, sheet_name_mapping[name]) for name in sheet_name_mapping}\n",
    "\n",
    "# Saving the merged data to a new Excel file\n",
    "OUTPUT_EXCEL_PATH = 'C:/Users/chspr/OneDrive/Desktop/SIT782/Merged_SleepStagingData.xlsx'\n",
    "with pd.ExcelWriter(OUTPUT_EXCEL_PATH, engine='xlsxwriter') as writer:\n",
    "    for subject_name, data in merged_data.items():\n",
    "        cleaned_sheet_name = subject_name.strip()\n",
    "        data.to_excel(writer, sheet_name=cleaned_sheet_name, index=False)\n",
    "\n",
    "# Confirm the path for download\n",
    "OUTPUT_EXCEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaaa20-b487-4d3f-aa06-871a00191271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the head of merged dataset\n",
    "merged_data['Subject 1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923b5e7d-171e-4067-95a7-5e2fb7bb3dcc",
   "metadata": {},
   "source": [
    "### checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c106e1c-4098-4e55-800f-58f8c0f3cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_summary = {sheet_name: data.isnull().sum().sum() for sheet_name, data in merged_data.items()}\n",
    "missing_values_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d696f00f-8bf2-40b5-82ad-20166ee85550",
   "metadata": {},
   "source": [
    "## data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98c0d9-4715-437f-8910-802bb742b198",
   "metadata": {},
   "source": [
    "the data in the given features are of different scales. so, we use standardization technique to normalise the data, where each feature will be scaled to have a mean of 0 and a standard deviation of 1. we are not normalising the class feature as it represents categorical label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd00fe8-b5be-40ec-a7f8-af1745760101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply normalization to each sheet in the dataset\n",
    "normalized_data = {}\n",
    "\n",
    "for sheet_name, data in merged_data.items():\n",
    "    # Select the features for normalization (excluding SubNo, SegNo, Class)\n",
    "    features_to_scale = data.drop(columns=['SubNo', 'SegNo', 'Class'])\n",
    "    \n",
    "    # Apply Min-Max scaling\n",
    "    scaled_features = scaler.fit_transform(features_to_scale)\n",
    "    \n",
    "    # Create a new DataFrame with normalized features\n",
    "    normalized_df = pd.DataFrame(scaled_features, columns=features_to_scale.columns)\n",
    "    \n",
    "    # Add the SubNo, SegNo, and Class columns back to the DataFrame\n",
    "    normalized_df['SubNo'] = data['SubNo'].values\n",
    "    normalized_df['SegNo'] = data['SegNo'].values\n",
    "    normalized_df['Class'] = data['Class'].values\n",
    "    \n",
    "    # Reorder columns to match original order\n",
    "    normalized_df = normalized_df[['SubNo', 'SegNo'] + list(features_to_scale.columns) + ['Class']]\n",
    "    \n",
    "    # Store the normalized DataFrame\n",
    "    normalized_data[sheet_name] = normalized_df\n",
    "\n",
    "# Display the first few rows of the normalized data for the first sheet\n",
    "normalized_data['Subject 1'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0a4ca-6028-4c8c-874b-0a036bafe249",
   "metadata": {},
   "source": [
    "## Finding Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332c4eaf-a145-45a8-856b-36d32600812f",
   "metadata": {},
   "source": [
    "There are many ways to find outliers in the dataset. here we are using Z-Scores to find the outliers. we will calculate the Z-Scores for all numerical columns, and identify any data points that have a Z-score less than -3 or greater than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b399329-5dc1-4376-ad99-0f3721d8d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Z-score calculation for each sheet and identifying outliers\n",
    "outlier_data = {}\n",
    "\n",
    "for sheet_name, data in normalized_data.items():\n",
    "    numerical_cols = data.select_dtypes(include='number').columns\n",
    "    z_scores = data[numerical_cols].apply(zscore)\n",
    "    \n",
    "    # checking outliers for numerical column with a Z-score greater than 3 or less than -3\n",
    "    outliers = (z_scores.abs() > 3).any(axis=1)\n",
    "    \n",
    "    # storing the outliers\n",
    "    outlier_data[sheet_name] = data[outliers]\n",
    "\n",
    "# Display the number of outliers\n",
    "outlier_data['Subject 1'], outlier_data['Subject 1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0053b35c-3456-4801-b6c8-40691e531b61",
   "metadata": {},
   "source": [
    "### Handling the outliers\n",
    "\n",
    "now to handle outliers we replace values where the Z-score is greater than 3 with the value corresponding to a Z-score of 3, and values less than -3 with the value at -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3b2c5-b8fb-414d-b174-e2efe048db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to cap values based on Z-score thresholds\n",
    "def cap_values(data, z_threshold=3):\n",
    "    numerical_cols = data.select_dtypes(include='number').columns\n",
    "    z_scores = data[numerical_cols].apply(zscore)\n",
    "    \n",
    "    # Calculating the capping thresholds\n",
    "    cap_high = data[numerical_cols] + (z_threshold - z_scores) * data[numerical_cols].std(ddof=0)\n",
    "    cap_low = data[numerical_cols] - (z_scores + z_threshold) * data[numerical_cols].std(ddof=0)\n",
    "    \n",
    "    # Applying capping\n",
    "    data_capped = data.copy()\n",
    "    data_capped[numerical_cols] = data[numerical_cols].where(~(z_scores > z_threshold), other=cap_high)\n",
    "    data_capped[numerical_cols] = data_capped[numerical_cols].where(~(z_scores < -z_threshold), other=cap_low)\n",
    "    \n",
    "    return data_capped\n",
    "\n",
    "# Applying the capping to each subject's data\n",
    "capped_data = {sheet_name: cap_values(data) for sheet_name, data in normalized_data.items()}\n",
    "\n",
    "# Displaying the results\n",
    "capped_data['Subject 1'].head(), capped_data['Subject 1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac95425-cd70-428a-9241-715ba38d608f",
   "metadata": {},
   "source": [
    "## building machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb56d22-067d-4cf7-814e-29eb7ab17f58",
   "metadata": {},
   "source": [
    "#### Splitting the data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d304697-1731-4401-9523-d741632c10e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Class' is the target variable\n",
    "features = capped_data['Subject 1'].drop('Class', axis=1)\n",
    "target = capped_data['Subject 1']['Class']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ce083-cc78-4dd2-8d46-f4f0047d9d07",
   "metadata": {},
   "source": [
    "### Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a45b9ce-12e0-4ae5-9995-4616b3099c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM Classifier\n",
    "svm_model = SVC(kernel='rbf', C=1.0, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a .pkl file\n",
    "PKL_FILENAME = \"C:/Users/chspr/OneDrive/Desktop/SIT782/svm_of_subject1.pkl\"\n",
    "with open(PKL_FILENAME, 'wb') as file:\n",
    "    pickle.dump(svm_model, file)\n",
    "\n",
    "# Output the filename where the model is saved\n",
    "PKL_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253fb42-6e82-4e46-93b9-3f7cf1325e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c42d969-100d-4e96-8949-4858ebc650b5",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03a96ed-4adb-4496-9ea3-edb2bf0d26db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a .pkl file\n",
    "PKL_FILENAME = \"C:/Users/chspr/OneDrive/Desktop/SIT782/randomforest_of_subject1.pkl\"\n",
    "with open(PKL_FILENAME, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "\n",
    "# Output the filename where the model is saved\n",
    "PKL_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c63d7-058f-4b9e-9df5-61c70a24275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c232269a-2f2e-4339-bbd4-5d2b8e19aaf3",
   "metadata": {},
   "source": [
    "The results from the SVM are quite concerning, showing a very poor performance for classes other than class 6, where it achieved a precision of 0.51 with a recall of 1.00, indicating it has predicted most data points as class 6.\n",
    "\n",
    "On the other hand, the Random forest model shows much better performance eith an accuracy of 76% and across all classes, with particularly strong results for classes 4 and 6. This suggests random forst might be a better fit for this dataset, or it handles the class imbalance more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e6d4a4-d4cc-4018-8c67-844a7679c6c6",
   "metadata": {},
   "source": [
    "### Now we build prediction model for all the subjects combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894d0548-89c2-4f78-9092-fe66740a46d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the capped data from all subjects into a single DataFrame for comprehensive analysis\n",
    "combined_data = pd.concat(capped_data.values(), ignore_index=True)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = combined_data.drop(columns=['SubNo', 'SegNo', 'Class'])\n",
    "y = combined_data['Class']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the shapes to confirm successful split\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0794a64-fa3f-4d7f-a37f-abe5a331a519",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7632125-5432-4414-9c06-f2ddf2e33c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "lr_model = LogisticRegression(max_iter=1000)  # Increased iterations for better convergence\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a .pkl file\n",
    "PKL_FILENAME = \"C:/Users/chspr/OneDrive/Desktop/SIT782/lr_of_combineddata.pkl\"\n",
    "with open(PKL_FILENAME, 'wb') as file:\n",
    "    pickle.dump(lr_model, file)\n",
    "\n",
    "# Output the filename where the model is saved\n",
    "PKL_FILENAME\n",
    "\n",
    "# Predict on the test set\n",
    "lr_predictions = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluation using classification report\n",
    "lr_report = classification_report(y_test, lr_predictions)\n",
    "lr_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79df9d78-f311-4e57-963c-346119f1c004",
   "metadata": {},
   "source": [
    "with all the subjects combined we have acheived the accuracy of 53% which is less compared to individual accuracy of subject 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d133739-89cc-4570-84a5-c687630c6c68",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7036822c-f7d6-460d-9afe-304829c0c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a .pkl file\n",
    "PKL_FILENAME = \"C:/Users/chspr/OneDrive/Desktop/SIT782/randomforest_of_combinedata.pkl\"\n",
    "with open(PKL_FILENAME, 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "\n",
    "# Output the filename where the model is saved\n",
    "PKL_FILENAME\n",
    "\n",
    "# Predict on the test set\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation using classification report\n",
    "rf_report = classification_report(y_test, rf_predictions)\n",
    "rf_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61492308-f044-4107-be65-848fd1530248",
   "metadata": {},
   "source": [
    "The Random Forest model produced accuracy of around 66%. it performed significantly better than the Logistic Regression model, showing improved accuracy and better handling of class imbalances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d7878e-9b3b-4dae-9422-13fb8a037625",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
